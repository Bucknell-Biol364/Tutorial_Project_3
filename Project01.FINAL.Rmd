---
title: "Group Project 3"
subtitle: "Biology 368/664 Bucknell University"
output: html_document
author: Prof. Ken Field
date: 9 Feb 2022
---
Dataset we are using: https://data.cdc.gov/NCHS/Provisional-COVID-19-Deaths-by-Sex-and-Age/9bhg-hcku/data

#INTRODUCTION TO EPIDEMIOLOGY:

Epidemiology is the "study of distribution and determinants of health related states among specified populations and the application of that study to control health problems" (A Dictionary of Epidemiology). The purpose of epidemiology in public health practice is to: (1) discover and analyze agents that affect heath, (2) determine causes of illness, disability, and death, (3) identify populations at risk, and (4) develop effective programs and services to to improve population health. Many epidemiologists solve health problems through a formal scientific approach that includes data collection, assessment, hypothesis testing, and action.  

The employment of epidemiology has been notably publicized by the COVID-19 epidemic. As many people have been impacted by the virus in various capacities, this has sparked curiosity into how professionals identify, measure, and represent the epidemiology of such infections. In this R tutorial, we will assume the role of an epidemiologist and conduct a formal scientific method using a COVID-19 dataset provided by the Centers for Disease Control (CDC).

At the conclusion of this project, the following should be accomplished:
  1. Relate epidemiology data collection to data science/analysis
  2. Carry out the scientific method
      a. Perform an exploration of the dataset using R 
      b. Perform basic data analysis using R
      c. Draw conclusions from the analysis
  
#INTRODUCTION TO R:

For many epidemiologists, the use of R Studio can be an effective program used to analyze collected data. As we are student epidemiologists, the aim of this tutorial and project is is to introduce the application of data analysis in R. Using R studio, however, may be a daunting task for those with limited experience with computer coding. This basic introduction to R serves to help alleviate such stress. Throughout the project, we will slowly add to a toolbox of coding techniques.

First, it is important to understand the different types of files you can use in R Studio. Today, we will go over R Markdown and R Notebook.

R Markdown files allow you to include text with embedded R code chunks. When the document is knitted and finalized you will be able to see the text, code chunks, and the output of those embedded chunks. This is a great tool for authors because it saves the time of copy and pasting graphs or tables into a report and aids in reproducibility. Using R Markdown allows others to see exactly what was done to produce the figures. 

R Notebook is quite similar to R Markdown except in a notebook only one line is sent at a time. In contrast R Markdown executes the entire code chunk at once. Another large difference is when a R Notebook file is rendered no code is re-run, only the code that has already been run will be presented in produced document. Whereas when an R Markdown file is rendered all code chunks are re-run and it will not allow you to convert it to a document if there is an error in a code chunk.  

##R Studio Basics. 

Code chunks can be created in the RMD file. This is where desired functions of analysis can be performed. The creation of a code chuck can be completed via clicking the green square "C" in the above toolbar, or by using the keyboard shortcut of cmd+option+I on macOS.

Additionally, one can transform their markdown file into a HTML, PDF, or word document. This is referred to as "rendering" and can be done by clicking on the Knit button up in the R Studio toolbar. When you press knit, it will run all of your code and create an output. If you want to omit the code but include the results of a chunk in your final document use echo = FALSE. If you want to omit the code and the results form the document use include = FALSE, as shown below. 

This code helps set up the R markdown document to make a nice clean html file for sharing. 
Click the green triangle to run the code chunk.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

To create headers in the text outside of the code chunk, once can place a single hash tag (#) in front of the text. For subheaders, use two hash tags (##). The following additions can be used to improve upon text:
  1.To italicized text, surround the text with asterisk (*).
  2.To bold text, surround it with two asterisks (**)
  3.To create a list, place on asterisk (*) in front of each line.

These additions may appear throughout the following project, but  would be more apparent if the RMD became knitted. The text will not appear italicized or bolded etc when you run your code, however, when the document has been finalized, the text will be altered accordingly.

<<<<<<< HEAD
Packages are collections of R functions, data, and compiled code which are stored in the library. The "System Library" can be found under the packages tab. The library will have checked boxes next to packages that are currently loaded into the current project. Packages can either be manually added (via instalation tab in "Packages") or coded in via a code chunk. For simplicity, all packages should be installed in the first code chunk, however, if a package is needed later in the project, it can always be added in later. A general list of packages one may want to always start off with include *dplyr*, *ggplot2*, *readr*, which is consistant of the tidyverce library (and should be added last).
=======
Packages are collections of R functions, data, and compiled code which are stored in the library. The "System Library" can be found under the packages tab. The library will have checked boxes next to packages that are loaded into the current project. Packages can either be manually added (via installation tab in "Packages") or coded in via a code chunk. For simplicity, all packages should be installed in the first code chunk, however, if a package is needed later in the project, it can always be added in later. A general list of packages one may want to always start off with include *dplyr*, *ggplot2*, *readr*, which is consistent of the tidyverse library (and should be added last in a code chuck).
>>>>>>> 7b48d59c42f02549de69522a2eb2be8dd379d332

Uses of the tidyverse library:
  1.dplyr: Summarizes data quick and efficiently.
  2.ggplot2: Data visualization 
  3.readr: Used read_csv()

In the example below, other packages are loaded into the project. These packages beyond tidyverse are:
  1.Cowplot: Additional package to ggplot; includes features to make publish ready figures
  2.Car: Used for statistical analysis; specifically linear models
  3.Stat2Data: Used to organize data in dataframe

Finally, the require function is used to ensure we actually get the package we want. If R Studio is unable to receive it, the code will come back with an error or FALSE.

Normally the R setup chunk can be included in the load libraries chunk, but I separated them today to allow for proper explanation.

```{r Load Libraries, include=FALSE}
# Load other packages here.
if (!require("cowplot")) install.packages("cowplot"); library(cowplot)
if (!require("car")) install.packages("car"); library(car)
if (!require("Stat2Data")) install.packages("Stat2Data"); library("Stat2Data")
if (!require("tidyverse")) install.packages("tidyverse"); library("tidyverse")
```

##Loading in Dataset

Here we will walk through how to load your data set in, and what each part of the code means.
  First on the left you put the name you want for your data set. 
  1. < - This assigns the data frame to a variable 
  2. read_csv reads the data into RStudio as a data frame
  3. within the parentheses is how you tell it where to find your data 
  4. the period (.) indicates that the data is located one folder or click away from your RMD file

Click this green arrow to run a chunk of code that produces output. If this code is successful, you should see "Covid_19" appear as a dataframe in the top right box of the R Studio interface under the "Environment" tab.

```{r Load in Data Set}
Covid_19 <- read_csv("./Data/Provisional_COVID-19_Deaths_by_Sex_and_Age.csv")
```

Click on the "Covid_19" dataset in the Environment tab and it will pull up a tab for you to view it. Before you start exploring your dataset, one should check to see if any column names have spaces in them. As R Studio has trouble reading spaces, it is easiest to rename these columns at the beginning of a project. 

In the code chunk below, the spaces in the column names are changed in incoorporate periods (.). This will make the data much easier to work with. After running the code chunk, check your dataframe to assure that the change was successful.

The structure of this function is as follows: names(dataframe)<-make.names(names(dataframe))

```{r}
names(Covid_19) <- make.names(names(Covid_19))
```

#EXPLORATION OF DATASET:

When a dataset is uploaded, there is an informal checklist to complete before visualization and analysis. One should become familiar with the elements in the dataset. The dataframe provides epidemiological data that is inclusive of: 
  1.Data "as of" date
  2.Start dates of data collection
  3.End dates of data collection
  4.Grouped data by month, year, or total
  5.Year of collected data (if applicable)
  6.Month of data collection (if applicable)
  7.State of data collection, or the entire United States
  8.Sex divided into male, female, or total
  9.Varied age groups or total collections 
  10.COVID-19 Deaths 
  11.Total Deaths
  12.Pneumonia Deaths
  13.Pneumonia Deaths and COVID-19 Deaths
  14.Influenza Deaths
  15.Pneumonia, Influenza, or COVID-19 Deaths
  16.Footnotes

These variables are all divided into their own column. Just by initially looking through these variables, one can notice some complexities that should be noted. This dataframe includes both summed total data and individual unit data. Thus, both broad and narrow analysis can be made using the dataset. For example, could could compare total deaths in the United States by age group, or one could look at total deaths by month, sex, and age group in a particular state. Caution should be used, however, when filtering the data when conducting an analysis to answer a particular question. Finally, for this dataframe, there are 82620 observations that can be inferred as individual points of collection. 

Key functions for visualizing data in R studio include:
  1. &: Narrows search between dataframe and column.
  2. ~: Comparison of variables that are "dependent on" one another; defines relationship between independent and dependent             variable.

##Formulating a Question: 

Once the variables of the dataframe have been assessed, one should formulate a question. Assuming this dataframe was given to an epidemiologist, they may be particularity interested in the time, state, sex, and COVID-19 Death  variables. Formulating a question at the beginning of data analysis can limit extraneous paths taken with a large dataset. A precise question and/or hypothesis can eliminate unnecessary variables from the subsequential analysis.

=======
The questions we are interested in for this R tutorial: 
1. Do males or females have more COVID-19 deaths per month? (Pennsylvania data)
2. Does west or east coast have more COVID-19 deaths?
3. Do older people have higher COVID-19 deaths?

The hypothesis(s) we are interested in for this R tutorial are: 
1. We hypothesize that there will be no difference in COVID-19 deaths between the to genders.
2. We hypothesize that there will be more COVID-19 deaths reported for the East coast.
3. We hypothesize that there will be more COVID-19 deaths reported for older individuals

##Read Data:

The next step in exploratory data analysis is to read in a portion of data. The purpose of this task is to determine if the data is "messy" and should be "cleaned". Messy data will often times not be orderly, have missing values, and is not suitable for immediate data visualization. As the data provided was from the CDC, we can expect relatively "clean" data. 

```{r}
library(readr)
summary(Covid_19)
```

The readr package is used here because it can read and analyze large dataframes fast. Also note the library notation of readr. This operation loads/attaches packages and stores them in the "System Library" located under the Packages tab. This is an exaple of reading in a package into a code chuck, but again, this package was already loaded at the beginning of the project.

The summary of the "Covid_19" dataframe can be performed to get a general idea of what type of data is included (character, integer, and numeric variables) and it also preforms a basic analysis of the numeric data by providing quartile ranges.

At the beginning of this project, we removed the spaces in the column names. Should they be changed at any point, the rename function can be used. The general structure of the rename function is as follows: dataframe (can make new or use original)<-rename(dataframe, new column name="column with spaces/Old name")

Run the example below, and then check to see if the column name is changed in the "Covid_19" dataset. This example will be preformed using a column *not* of interest to our question(s)/hypothesis(s).

```{r}
Covid_19<- rename(Covid_19, Influenza = "Influenza.Deaths")
```

For practice, try renaming the "Pneumonia.Deaths" to "Pneumonia" using this structure outline. Furthermore, one can add a code chunck in the RMD markdown file by clicking the green square "C" in the above toolbar, or by using the keyboard shortcut of cmd+option+I on macOS.

```{r}

```

##Check Packaging:

Next, the packaging of the dataframe should be assessed. This validates that the dataframe is complete and is properly loaded. This can be complete using simple R commands. We can look at the number of columns and rows that the dataframe has. 

```{r}
ncol(Covid_19)
nrow(Covid_19)
```

As the output of this code chuck matches the expected number of variables and observations (as displayed in the "Global Environment"), it can be assumed that the dataframe was uploaded correctly (although it can be checked by creating a table; a function performed later in this section). 

##Run str()

Another general exploration tool that should be completed before analysis is running the structure of the dataframe. The output of this command replicates some knowledge we already have, however, it is another clean visual of the composition of the data and is an additional method to catch potential problems in the dataframe before analysis. 

```{r}
str(Covid_19)
```

Immediately, one may notice the NA values listed for the year and month columns. These should be further evaluated. By rescrolling through the "Covid_19" dataframe, we can note that these NA values come from data that has been grouped. Grouped data as such makes the year and month values obsolete. "By total" data may be useful for future data as it is clean and easy to work with. Less filtering, as we will discuss later, may be required. 

Beyond the NA values in the dataframe, there appears to be no other apparent issues. For future analysis using R beyond this project, however, NA values should always be evaluated as it could indicate missing variables or erroneous data that can not be used.

##Check Top and Bottom of Data:

Assessing the beginning and end of the dataframe is a useful tool to assure the data was loaded in property, the data is properly formatted, and that all expected data is present. Should dates be present in the dataframe, this technique is useful to check the ordering of them.  

The "Covid_19" dataframe has dates and the ordering should be evaluated. This can be completed via the head and tail R commands. The structure of this commands is as follows: head/tail(dataframe[, c(column:column, #rows)]).

The brackets in this structure are a useful way to filter data via the use of a preloaded packaged (dplyr). An immediate comma is placed after the bracket to specify the filtering of data from a column. Typical use of brackets are structured as [row, column]. The c command allows for a string of commands. Finally, we can specify a range of columns of interest and the number of rows of data desired. 

```{r}
head(Covid_19[, c(1:3, 10)])
tail(Covid_19[, c(1:3, 10)])
```

By looking at the start dates, we can see that the dataframe is logical. At the head (first ten rows), the data collection start date began in January of 2020. At the tail of the dataframe (last ten rows), the start date began in February of 2022. 

Additionally, the tail command can be useful for identifying extraneous values or information placed at the end of the dataframe.

##Check Observations (N's):

For data exploration, it is helpful to identify landmarks within a dataframe that can be used to check against the data being evaluated. This can be done a number of ways, but simply, a table can be made. For example, the "Covid_19" dataframe has distinguished variables that look at Sex and State observations. These variables can be crosschecked by the analysist to assure that the expected amount of observations are present. 

The table function can be utilized in R. The structure of the command is as follows: table(dataframe$variable). The dollar sign can be used to narrow analysis by column within a dataframe.

```{r}
table(Covid_19$Sex)
table(Covid_19$State)
```

The net number of observations from each variable category (whether sex or state) should equals the amount of observations present in the dataframe, as there should be one entry for every observation. In this case, the numbers within each column matches the total number of observations, which is reassuring (27540 x 3 "sex categories = 82,620 observations, and 1,530 x 54 "states" = 82,620 observations). 

By looking at the states, however, we note that Puerto Rico, District of Columbia, New York City, and United States area all included on the dataset. While these locations have been included because they are US territory, locations of interest, or label data representative of the entire country instead of a state, this is important to take note of. It is up to the epidemiologist, in later sections, to determine whether these locations should be included in analysis depending on the question at hand, but this is a prime example of how exploring the dataset is an essential step when working with R Studio.

##Other Checks to Consider:

After an initial check over the dataframe has been complete, there are other factors to consider. For this purpose of this R tutorial, they will not be completed in full, but rather highlighted as things to be consider when conducting data analysis beyond this project. The first additional rule of thumb to consider is the validation of ones own data via a comparison with an external source. The CDC is very reliable, thus, the observations in this dataframe do not necessarily have be check. However, should further investigation be complete, eternal sources to consider include datasets from Johns Hopkins or Our World in Data.
If one is using their own reseach data, they would certainly attemp an external validation of data. They would want to compare observations and numeric variables against another reliable source to conclude the absence of erroneous data. 

An additional consideration is to try to answer ones question/hypothesis in the easiest way possible. Say your question simply asks which state had the most COVID-19 death in 2020. The data can simply be filtered out using a table. Certain questions like these do not need further exploration. The solution to these questions, however, should be challenged if possible. Factors such as some states not reporting data could be an issue (this is one such example, but this problem is not present in the "Covid_19" dataframe).

The purpose of this concluding paragraph on exploration of a dataset is to raise the point that not all questions require a deep dive into data analysis, rather, just a basic R exploration. Questions that compare variables, look at causality, and evaluate relationships, however, do require a lengthier analysis. 

#VISUALIZATION OF DATASET AND VARIABLES OF INTEREST:

Before we begin visualization of our dataset, we should familiarize ourselves with some key ggplot functions. Below is a general template with explanations of functions that one can use when creating a plot.

Create a graph name and graph using the ggplot package 
    a. Think of a title for the plot. Redefine dataframe via <-ggplot()
    b. The structure of a basic ggplot is as follows: (data.frame, aes(x=column, y= column))
      -Unless specified, R will choose the best fit plot with the given data (it might not be the desired plot you want)
      -aes= axis. Define the x and y axis of your plot by the independent and dependent variable. 
    c. Specify the plot you wish ggplot to create. Lets create a point plot with a line. The structure of this command is as             follows: geom_() 
        -Geom_point creates a line graph. You can leave it here or add a binary variable
        -Binary variables can be distinguished by the function colour =factor(BV). 
        -All data points can be added via the jitter command. Add position= "jitter". This is useful for visualize independent            data points
        -The size and transparency of these data points can be defined using the commands alpha= and size=
    d. If desired, specify a line of best fit with standard deviation. Use command geom_smoooth. The structure of this command is         as follows:
        geom_smooth(formula = y ~ x,method='lm',aes(group = factor(BV), colour = factor(BV))) 
        -The formula is specified as y~x as a linear line is desired
        -Method='lm" to specify a linear model
        -Group and colour should equal factor of the binary variable
    e. Clean the graph up by changing:
        -Change legend position by using theme function of ggplot: theme(legend.position = "right, left, top, bottom")
        -Change title of plot via function: ggtitle("Title")
        -Change name of x/y axis and legend title via function: labs(x= "X Title", y= "Y Title", color= "Legend Title") OR you             can individually state the x/y axis labels via xlab("Title") and ylab("Title")
        -Change aesthetics of x axis categories via function: theme(axis.text.x = element_text(angle = 1-180, vjust = numeric,            hjust=numeric))
    f. A string of commands can be accomplished using "+" after each line of code.
    g. Apply theme_cowplot() which provides a classical plot appearance with two axis lines and no background grid
    h. Plot using function plot(name of designated plot)
    
    
Above is general outline that can be modified. Elements can be added or removed based on desired aesthetic appearance. The ggplot packaged also plots more than line graphs. A master list can be found at this link: 

http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html

1. Plotting Data of COVID-19 Deaths by year and month. 

This is a great way to start looking at the data set. Here we can get a visualization of how the data is spread out over years and then narrow in per month. 

This first plot shows COVID-19 Deaths per year.

The plotting of this question and data requires the use of the filter function. Specific observations can be filtered from the "Covid_19" data frame. This can be completed using the highly useful "filter" command. The structure of the filter command is as follows: new data frame name<-filter(old data frame name, column==/!=/>=/<= "Info from column")

Filtering can be accomplished by specifying what one would like to take/remove from the original data frame. One can use the following to: 
  ==: Specify data that is equivalent to (think keep data)
  !=: Specify data that is not equal to (think remove data)
  <=: Specify data less than desired numeric data (use greater than sign for reverse process)
  &: Multiple filter commands; make a string of commands

Listed above are simply introductory commands that are used in conjunction with the filter command. Keep in mind, however, there are additional commands like is.na(), between(), and near() that can be used for advanced filtration. For the purpose of this project, we will mainly focus on the introductory commands. 


```{r}
CovidFilter <- filter(Covid_19, Group == "By Month")
CovidYear <- group_by(CovidFilter, Year, Month)

ggplot(CovidYear) +
  geom_jitter() + 
  aes(x= Year, y= COVID.19.Deaths) + 
    ggtitle("Covid 19 Deaths per Year") + 
  xlab("Year") + 
  ylab("Covid 19 Deaths") + 
  geom_point() + 
  theme_cowplot()
```
<<<<<<< HEAD


Here we can visualize if there is a difference in COVID-19 Deaths per month. The graphs are organized per year so we can also look to see if the trends differ by year.
=======

Here we can visualize if there is a difference in COVID-19 Deaths per month.

Additional modifications to the plotting outline are needed. One can use the dplyr function group_by to group desired data from different columns/variables in a dataframe. In addition, we want to run the Month X-variable as a factor, instead of a numerical variable. This distinction is made within the aes() function, and is necessary to obtain the appropriate x-axis values. If you are curious about this functions effect, change "aes(x= factor(Month), y= COVID.19.Deaths)" to "aes(x= Month, y=COVID.19.Deaths)" for graph p1 and note the difference.

>>>>>>> 289479845bd9a1b24291f0059c577abb2143747d
```{r}
CovidFilterMonth1 <- filter(Covid_19, Group == "By Month", Year == "2020") #filter is used here to filter out all groups that are not organized by month. We also filtered by the Year so we will only see data for 2020.
CovidMonth1 <- group_by(CovidFilterMonth1, Year, Month) #group_by is used to group the data into Year and Month

# p# is used below to lable each graph to make it easier to visualize them together later.
p1 <- ggplot(CovidMonth1) +
  geom_jitter() + 
  aes(x= factor(Month), y= COVID.19.Deaths) + 
    ggtitle("Deaths per Month in 2020") + 
  xlab("Month") + 
  ylab("Covid 19 Deaths") + 
  geom_point() + 
  theme_cowplot()

CovidFilterMonth2 <- filter(Covid_19, Group == "By Month", Year == "2021")
CovidMonth2 <- group_by(CovidFilterMonth2, Year, Month)

p2 <- ggplot(CovidMonth2) +
  geom_jitter() + 
  aes(x= factor(Month), y= COVID.19.Deaths) + 
    ggtitle("Deaths per Month in 2021") + 
  xlab("Month") + 
  ylab("Covid 19 Deaths") + 
  geom_point() + 
  theme_cowplot()

CovidFilterMonth3 <- filter(Covid_19, Group == "By Month", Year == "2022")
CovidMonth3 <- group_by(CovidFilterMonth2, Year, Month)

p3 <- ggplot(CovidMonth3) +
  geom_jitter() + 
  aes(x= factor(Month), y= COVID.19.Deaths) + 
    ggtitle("Deaths per Month in 2022") + 
  xlab("Month") + 
  ylab("Covid 19 Deaths") + 
  geom_point() + 
  theme_cowplot()

plot_grid(p1,p2,p3,ncol=2) #plot_grid allows us to plot all of the graphs next to one another for easier comparison
```

2. Plots tp visualize if older individuals have higher death rates than younger individuals.

You may have noticed comments being made in code chucks that do not interfere with running the code. These are denoted with a # and are shown in green. This is valuable tactic used to walk individuals (familiar or unfamiliar with the dataframe) through thethe code. 

Furthermore, note in this next code chuck, the operator %>% will be utilized from the Dplyr package to allow for pipeline commands. This is a close equivalent to using "+" in ggplot.

```{r}
library(dplyr) #Calls the dplyr package to run subsequential code
Covid_19 %>% #Calls the Covid_19 dataset to be acted on by the following functions
  filter(State == "United States") %>% #Selects only the data total deaths in the United States independent of State
  filter(Sex == "All Sexes") %>% #Selects deaths from all sexes, excluding repetitive Male/Female subdivisions
  filter(Group == "By Total") %>% #Selects total deaths to date, excluding repetitive by month/year subdivisions
  summarize(State, Sex, Age.Group, COVID.19.Deaths) -> Covid_19.Deaths.by.Age #Selects only the relavent columns to our analysis and saves them to a new dataset titled "Covid_19.Deaths.by.Age"

table(Covid_19.Deaths.by.Age$Age.Group)
```

After running this new code chuck, the new data frame "Covid_19.Deaths.by.Age" was created from the previous "Covid_19" data frame, and is present in the "Global Environment"/Environment tab. In this data frame, one will notice that only 17 of the original 82620 observations are included, with only the 4 variables/columns of data specified by the summarize function above. Furthermore, notice how "State=="United States"" command kept data from that one particular "State". Additionally, note how the same is true for observations categorized as "All Sexes" and "By Total" in the Sex and Group column.

This general theme of grouped data, as mentioned earlier in the project, is something to beware of. Be cautious when analyzing data and filtering data for statistical analysis. 

However, as our table function shows above, our filtering process is not complete. Notice that some of the listed age ranges have repetitive data, and if one aims to make a coherent graph, one should not have overlap between age groups. In addition, note that the adolescent observations collected data at a different age intervals that are not consistent with the way the adult age intervals collected. Thus, one is forced to look at age range 0-1 years for newborns, 1-4 years for young children, followed by a consistent 9 year interval range through adult hood. 

This is OKAY, but should be noted with analysis. There was simply inconsistency with data collection that is beyond our control.

The code below shows how we can eliminate Ages that overlap with the "!=" operator in the filter command. 

```{r}
Covid_19.Deaths.by.Age %>%
  filter(Age.Group != "0-17 years" & Age.Group != "All Ages" & Age.Group != "50-64 years") ->Covid_19.Deaths.by.Age #removing 0-17 years, All Ages and 55 - 64 years observations, and saves the resulting data frame over the preexisting one (note the number of observations decreasing to 14)

table(Covid_19.Deaths.by.Age$Age.Group)
```

While we are close to being able to plot this data, the order in which the years are listed is skewed. This order would be reflected on our graph if we were to choose to graph this subset of our data without further modification. By using the "recode_factor" function below, we can rename the groups so that automatic numerical ordering will place them in a coherent order. 

The format for the recode factor matches the following:
"dataset$specific.column.in.dataset<-recode_factor(dataset$specific.column.in.dataset, `Previous Name`="New Name", etc.)


```{r}
Covid_19.Deaths.by.Age$Age.Group<-recode_factor(Covid_19.Deaths.by.Age$Age.Group, `Under 1 year` = "0-1 years", `1-4 years` = "01-4 years", `5-14 years` = "05-14 years")

table(Covid_19.Deaths.by.Age$Age.Group)
#validating change
```

Notice how now the years are ordered in a logical manner, and we are ready to graph the data.

The following steps take place in order to perform this. This code extends upon the steps used in part 1 of this data visualization section (again, note the comments explaining what each line of code is doing):

```{r}
library(ggplot2) #Calls the ggplot package for use in subsequent code
US.Deaths.by.Age<-ggplot(data=Covid_19.Deaths.by.Age) + #Saves the produced graph as "US.Deaths.by.Age" to Environment tab
  aes(x=Age.Group, y=COVID.19.Deaths) + #defines variables for the X and Y axis
  geom_bar(stat="identity") + #Defines the graph as a bar graph with Y values that are identical to the observational values
  ggtitle("COVID-19 Deaths by Age in the United States") +
  labs(x= "Age Group", y= "COVID-19 Deaths") +
  theme(axis.text.x = element_text(angle = 50, vjust = 0.7, hjust=0.5)) #adjusts x-axis positioning
  

US.Deaths.by.Age #Calls previously created graph to be displayed

```

3. Code for Ranking net Deaths by State 

We can also sort the data to see which state has the most Covid_19 deaths over the course of the pandemic. By now, you should have a toolbox of coding techniques large enough to follow along with this analysis. Functions that have not been previously shown will have a comment explaining them next to them with general descriptions.


```{r}
library(dplyr)
Covid_19$State<-as_factor(Covid_19$State)
nlevels(Covid_19$State) #Shows us how many observations are within each level (or State) of the factor.
table(Covid_19$State) #Shows us the number of different "State" values there are by showing a number of how many unique levels the vector has

Covid_19%>%
  filter (State != "United States" & State != "District of Columbia" & State != "New York City" & State != "Puerto Rico") %>%
  filter(Group == "By Total") %>%
  filter(Sex == "All Sexes") %>% 
  filter(Age.Group == "All Ages") ->Covid_19.State.Deaths
```

To ensure the filtering process worked and observe the results:

```{r}
table(Covid_19.State.Deaths$State)
nlevels(Covid_19.State.Deaths$State)

arrange(Covid_19.State.Deaths,desc(COVID.19.Deaths)) #arranges the data from the state with the highest number of deaths to the state with the lowest number of death
```
Notice the first output frame shows that one observation (the data point representing the total number of deaths in each state since the start of the pandemic) remains in each state. Although there are 54 states total in the list, the ones removed (United States, District of Columbia, New York City, and Puerto Rico) all have no observations in their category, effectively taking them out of the set. And finally, the second box shows us the order of States with the most to least Covid-19 deaths with California being first (85,545 deaths).

4. West Coast vs East Coast COVID-19 Death Exploration 

Looking at differences in COVID-19 deaths between the East and West coast creates a problem in our original dataset. We have no segregation between these two variables. Thus, we must do so ourselves, and this can be completed via the creation of a new column in our original "Covid_19" data frame. 

The creation of a new data frame with an additional column that segretates the East and West coast states can be accomplished using the mutate command. A new column can be created that creates binary values of "TRUE" or "FALSE" where, for example, "TRUE" is equivalent to states on the West coast and "FALSE" is equivalent to states on the East coast. 

One can use the Dpylr package to mutate their data frame. This package is already preloaded into our RMD. 

The structure of the mutate command is as follows: data frame%>% mutate(Added column=Column manipulated %in% c(specification of desired data)). This "filtered" should be replaced into data frame (new or old)-> data frame.

Note <- and -> are the same function, but placement at the begging or end of code specify usage. 

Lets add a new column into the "Covid_19" data frame and call it WC for West Coast.

```{r}
Covid_19%>%
  mutate(WC= State %in% c("Alaska","Arizona","Arkansas","California","Colorado","Hawaii","Idaho","Iowa","Kansas","Louisiana","Minnesota","Missouri","Oregon","South Dakota","Texas","Utah","Washington","Wyoming"))->Covid_19
```

**Check to make sure new column as been added by opening up "Covid_19" from the environment.

Now, lets utilize this new column and plot West coast vs East coast COVID-19 death by sex while applying the same coding techniques learned from previous sections. We should make a boxplot. In this code chuck, we will exclude data from the "States" labeled "United States", "New York City" , and  "Puerto Rico" because these are not traditional states. Washington DC data will remain included based on preference.

Finally, we will add one new line of code. We can change the x axis labels by incorporating the function: scale_x_discrete(labels = c('Title', 'Title')). We will want to specify East from West coast. Without this code, the lables will show up as "FLASE" and "TRUE".

```{r}
CovidDataCoasts<-filter(Covid_19, Group=="By Total" & Sex!="All Sexes" & Age.Group=="All Ages" & State!="United States" & State!="Puerto Rico", State!= "New York City" )
Coast1<-ggplot(CovidDataCoasts) +
  aes(x=WC , y=COVID.19.Deaths) +
  geom_boxplot() +
  geom_jitter(width=.15, aes(color=Sex)) +
  ggtitle("Total Covid-19 Death vs East/West Coast") +
  labs(x="Coast", y="COVID-19 Deaths") +
  scale_x_discrete(labels = c('East', 'West')) +
  theme_cowplot() +
  theme(axis.text.x = element_text(angle = 0, vjust = 1, hjust=0.5))
plot(Coast1)
table(Covid_19$State)
```

Additionally, we can plot West coast vs East coast deaths by age range. Again, we will filter the age groups we wish to represent. 

One additional line of code can be included. We can specify the labels of the legend and the color of the represented binary factor. This can be accomplished via the command:scale_colour_manual(labels=c("Title", "Title"), values= c("color", "color"))

Colors can be represented numerous ways in R. However, they can be conveniently picked by utilizing this provided resource from Columbia University.

http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf 

This cheat sheet was created by Dr. Ying Wei.

```{r}
CovidDataCoasts1<-filter(Covid_19, Group=="By Total" & Age.Group!="All Ages" & Age.Group!="Under 1 year" & Age.Group!="1-4 years" & Age.Group!="5-14 years" & Age.Group!="15-24 years" & Age.Group!="25-34 years" & Age.Group!="35-44 years" & Age.Group!="45-54 years" & Age.Group!="55-64 years" & State!="United States" & State!="Puerto Rico", Sex!="Male" & Sex!="Female")
Coast2<-ggplot(CovidDataCoasts1, aes(x = Age.Group, y = COVID.19.Deaths)) +
  geom_point(aes(colour = factor(WC)), 
             position = "jitter", 
             alpha = 0.8,
             size=0.05) +
  geom_smooth(formula = y ~ x,method='lm',aes(group = factor(WC), 
                              colour = factor(WC))) + 
  theme(legend.position = "right") + 
  ggtitle('Covid-19 Deaths by Age Group (Total) ') +
  labs(x= "Age Group", y= "COVID-19 Deaths", color="Legend") +
  scale_colour_manual(labels=c("East", "West"), values= c("darkblue", "red")) +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=0.5))
  theme_cowplot()
plot(Coast2)
```

5. Plotting Data of COVID-19 Deaths from Pennsylvania (Total)

To really narrow analysis, we can further look at the number of COVID-19 deaths per year and month in Pennsylvania. The state of Pennsylvania was chosen for epidemiological relevance. Furthermore, refining the dataset to a single state is beneficial for improved data visualization. 

```{r}
PennData<-filter(Covid_19, Sex!="All Sexes" & State=="Pennsylvania")
```

After running this new code chuck, note the new data frame "PennData" created from the "Covid_19" data frame.

This data frame can be further refined using the filter function to explore COVID-19 deaths by Age, Group, and Year similar to as what was previously completed in earlier sections. Note that the filtered "PennData" data frame is now being saved as "CovidDataPennTotal", and that the number of observations in the data frame is decreasing as we continue to focus in on certain data. 

The problem of adolescent observations having different age intervals that are not consistent with the way the adult age intervals collected is one again a problem here, however, the age groups that are included in the analysis are broken up differently. See if you can look at the filter code below before running the analysis, compare it to the code in part 2 of the "Visualizing the Data" section, and see how the filter code for age ranges differs.

```{r}
CovidDataPennTotal<-filter(PennData, Group=="By Total" & Age.Group!="All Ages" & Age.Group!="Under 1 year" & Age.Group!="1-4 years" & Age.Group!="5-14 years" & Age.Group!="15-24 years" & Age.Group!="25-34 years" & Age.Group!="35-44 years" & Age.Group!="45-54 years" & Age.Group!="55-64 years")
```

```{r}
PennTotal<-ggplot(CovidDataPennTotal, aes(x = Age.Group, y = COVID.19.Deaths)) +
  geom_point(aes(colour = factor(Sex)), 
             position = "jitter", 
             alpha = 0.8,     #Change transparency for aesthetics
             size=1.0) +      #Change size for aesthetics
  geom_smooth(formula = y ~ x,method='lm',aes(group = factor(Sex), 
                              colour = factor(Sex))) + 
  theme(legend.position = "right") + 
  ggtitle('Covid-19 Deaths by Age in Pennsylvania (Total) ') +
  labs(x= "Age Group", y= "COVID-19 Deaths", color= "Gender") +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=0.5))
  theme_cowplot()
plot(PennTotal)
```

A great, refined, visualization was created! Lets take the same code structure from the previous code chunk and look at COVID-19 Deaths from Pennsylvania by month. The creation of a new data frame, filtering, and creation of a new plot name should be applied. The next plot is a manipulation of the x axis (change to Month) and factor (change to Year). Of course, dress the plot up by changing plot titles.

One additional line of code, however, should be included to change the x axis numeric categories (which represent the numeric month) to a character (month name). This can be accomplished using the already loaded package "Stat2Data". The command structure is as follows: scale_x_continuous(breaks = seq_along(month.name), labels = month.name). This line changes the month observation of "2" to display as February on the X axis.

(Line taken from https://stackoverflow.com/questions/69411847/changing-month-from-number-to-full-month-name-in-r)


```{r}
library(Stat2Data)
CovidDataPennMonth<-filter(PennData, Group=="By Month" & Age.Group=="All Ages")
PennMonth<-ggplot(CovidDataPennMonth, aes(x = Month, y = COVID.19.Deaths)) +
  geom_point(aes(colour = factor(Year)), 
             position = "jitter", 
             alpha = 0.8,
             size=0.05) +
  geom_smooth(formula = y ~ x,method='lm',aes(group = factor(Year), 
                              colour = factor(Year))) + 
  scale_x_continuous(breaks = seq_along(month.name), labels = month.name) +
  theme(legend.position = "right") + 
  ggtitle('Covid-19 Deaths by Month in Pennsylvania ') +
  labs(x= "Month", y= "COVID-19 Deaths", color="Year") +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=0.5))
  theme_cowplot()
plot(PennMonth)
```

This is a neat visual. Notice how the year 2022 only has two months of data collection. If statistical analysis were to be completed with this graph, the year 2022 would likely be removed as no informative comparison can be made using a variable that has incomplete data collection.

We can also take a look at monthly COVID-19 deaths between Female/Males in Pennsylvania. Again, the same formula of data visualization will be utilized, however, this time we will try using boxplots and density plots. Boxplots are a great graphing tool to apply to look for outlying data. Density plots are beneficial for looking at the representation of the distribution of a numeric variable. 

Specify the geom_ of the plots by inserting geom_boxplot or geom_density into the code. Finally, theme_cowplot() allows users to plot the graphs in specified frames using the function: plot_grid(name, name, ..., ncol=#).

```{r}
PM1<-ggplot(CovidDataPennMonth) +
  aes(x=Sex , y=COVID.19.Deaths) +
  geom_boxplot() +
  geom_jitter(width=.15, aes(color=Sex)) +
  ggtitle("Monthly Covid-19 Death vs Sex In Pennsylvania") +
  labs(x="Sex", y="COVID-19 Deaths") +
  theme_cowplot() +
  theme(axis.text.x = element_text(angle = 0, vjust = 1, hjust=0.5))
  
PM2<-ggplot(CovidDataPennMonth) +
  aes(x = COVID.19.Deaths, fill = Sex) + 
  geom_density(alpha=.3) +
  labs(x= "Deaths", y="Density", title="Density vs Monthly Covid-19 Deaths In Pennsylvania")
  theme_cowplot()
  
  
plot_grid(PM1,PM2, ncol=1)
```

Finally, lets plot COVID-19 Deaths from Pennsylvania by year.

```{r}
CovidDataPennYear<-filter(PennData, Group=="By Year" & Age.Group=="All Ages")
PennYear<-ggplot(CovidDataPennYear, aes(x = Year, y = COVID.19.Deaths)) +
  geom_point(aes(colour = factor(Sex)), 
             position = "jitter", 
             alpha = 0.8,
             size=0.05) +
  geom_smooth(formula = y ~ x,method='lm',aes(group = factor(Sex), 
                              colour = factor(Sex))) + 
  theme(legend.position = "right") + 
  ggtitle('Covid-19 Deaths by Month in Pennsylvania ') +
  labs(x= "Year", y= "COVID-19 Deaths", color="Gender") +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=0.5))
  theme_cowplot()
  
plot(PennYear)
```


#STATISTICAL ANALYSIS:
### I think we do age above 50 vs age below 50, W vs. E, no diff in the two genders

As a reminder, the hypotheses we are interested in for this R tutorial are: 
1. We hypothesize that there will be more COVID-19 deaths reported for the East coast.
2. We hypothesize that there will be more COVID-19 deaths reported for older individuals in PA.
3. We hypothesize that there will be no difference in COVID-19 deaths between the to genders in PA.

In order to test these hypotheses, we will be creating linear models working solely with total deaths, or the "By Total" level of the "Group" column. This will allow is to avoid having to run a statistical analysis on a time series, which is something we are not covering in this tutorial.

The first linear model we will be running will be used to determine if the total number of Covid-19 deaths on the East Coast is significantly different from those on the West Coast. The output of the linear model function will be used to explain the statistical analysis, but for now just follow along with the basic code format for a linear model:

lm(Response/Dependent Variable ~ Predictor/Independent Variable, data=data.frame)

Notice that the product of this function is assigned the identity "lmEvsW" for East vs. West Coast. This analysis is performed using the CovidDataCoasts dataset, with both male and female sexes, by total, All Ages, excluding "United States", "New York City", and "Peurto Rico". The 102 observations are present within the data frame are 2 per "state" (one for female deaths, one for male deaths) for 51 "states" (the traditional 50 states + the District of Columbia). The summary(lmEvsW)
plot(lmEvsW) functions should always be ran in tandem with the execution of a linear model in order to ensure the model can be assessed. Briefly look at the output below after running the code chunk, and then follow the text below the output describing the results of a linear model.

```{r}
lmEvsW <- lm(COVID.19.Deaths ~ WC, data=CovidDataCoasts)
summary(lmEvsW)
plot(lmEvsW)
```

The assumptions required to perform a linear model include the following:
1) Linearity: The relationship between X and the mean of Y is linear, or the X variable is categorical. In this case, we are comparing East Coast vs West Coast binomial categories, so we don't have to check for linearity. In fact, we are only going to be analyzing categorical X variables for the remainder of this tutorial, so this constraint is not relevant to our analysis.

2) Homoscedasticity: The variance of the residuals is random for each X value. Select the second output frame above. Because we are looking at a categorical variable, our X values become these 2 categories (east and west coast). Notice that the distribution of residuals is fairly consistent across both X values.

3) Independence: Observations are independent of each other. We can determine from intuition that the number of Covid-19 deaths are not dependent on the State name. It is still possible that State may have an effect on Covid-19 deaths, but this is different than "state" being dependent on Covid-19 deaths.

4) Normality: For any fixed value of X, Y is normally distributed. Select the 3rd output frame. This can be evaluated from a qqplot, which you likely remember from your statistics course. If the points are distributed along the line, then the Y values are normally distributed for each X value.

Notice that we do not have normal distribution for this analysis. This does not make our linear model entirely not compatible with the data, but does require that we interpret the results with caution. 

Interpreting Significance:
Select the first output frame above. Theoretically what this linear model is doing is fitting a horizontal line through the weighted mean Y value for one category of X (call this X1). Then, the linear model is comparing the weighted mean Y value for X1 to the weighted mean Y value of category X2 and determining the probability (p value) that these two weighted mean values come from the same population. A linear model is capible of comparing a number of categorical variables like this, making it very useful.

Look under the "Coefficients" detection of output frame 1. "(Intercept)" shows the baseline X value that the rest are being compared to. RStudio automatically selects the baseline category for comparison by alphabetical order. Although it is not explicitly stated, this category above is "WCFALSE", and WCTRUE is being compared to this baseline. Now, study the WCTRUE line of values. These say the following. WCTRUE Covid-19 deaths (or the total ) 151.9     

1967.3   0.077    0.939


2. We hypothesize that there will be more COVID-19 deaths reported for older individuals in PA.

```{r}

PennData$Age.Group<-recode_factor(PennData$Age.Group, `Under 1 year` = "0-1 years", `1-4 years` = "01-4 years", `5-14 years` = "05-14 years")

PennData%>%
  filter(Group=="By Month" & Year!="2022") %>%
  filter(Age.Group != "0-17 years" & Age.Group != "All Ages" & Age.Group != "50-64 years") ->Covid_19PA.OldvsY

lmOvsY <- lm(COVID.19.Deaths ~ Age.Group, data=Covid_19PA.OldvsY)
summary(lmOvsY)
plot(lmOvsY)
```

3. We hypothesize that there will be no difference in COVID-19 deaths between the to genders in PA.

```{r}
shapiro.test(CovidDataPennMonth$COVID.19.Deaths)
shapiro.test(CovidDataCoasts1$COVID.19.Deaths)
shapiro.test(CovidDataCoasts$COVID.19.Deaths)

CovidDataPennMonth1<-filter(PennData, Group=="By Month" & Age.Group=="All Ages" & Year!="2022")
lmCDM1 <- lm(COVID.19.Deaths ~ Sex, data=CovidDataPennMonth1)
summary(lmCDM1)
plot(lmCDM1)
```




## Target Audience

Upper level epidemiology class using R Studio for the first time.

## Grading

Each student will be expected to complete the following tasks to earn 85% of the points available for this assignment (21/25).

- Identify and obtain suitable dataset
- Use a Github repository and version control to collaborate on the project
- Spend 4-6 hours preparing, coding, and testing tutorial
  + Data exploration
  + Data visualization
  + Hypothesis testing
- Present tutorial in class
- Provide public archive suitable for sharing to students/faculty

Tutorials from previous classes can be viewed at our public github site: https://github.com/Bucknell-Biol364

Additional credit will be awarded for providing assistance to other groups and for the development of a tutorial that goes beyond the minimal expectations listed above.


# Acknowledgements
Outline:
README(Maisy)
1) Introduction to class (Ashley)
2) Introduction to R (Maisy)
    Define RMD vs Regular R
    Loading Data Set
    Load Packages
    Refer to glossary for a function/stats overview…
3) Explore Data Set (with function explanations) (Ashley)
    Formulate a question
    Read data
    Check packaging 
    Run structure
    Look at top and bottom of data
    Check your n’s
4) Visualize Data Set
    1. Timeline vs death (Maisy)
    2.Rank net deaths by state (Ben)
    3.Do older people have higher death rates than younger (Ben)
    4.West coast vs east coast (Ashley)
    5.Covid-19 Deaths in Pennsylvania (Ashley)
5) Statistical analysis to answer hypothesis(Ben)
   1.We hypothesize that there will be more COVID-19 deaths reported for the East coast.
   2.We hypothesize that there will be more COVID-19 deaths reported for older individuals in PA.
   3.We hypothesize that there will be no difference in COVID-19 deaths between the to genders in PA.




